import * as lib_abort from "./lib_abort.js"
import {EMPTY, LF} from "./lib_char.js"
import * as lib_datetime from "./lib_datetime.js"
import * as lib_git_message_prompt from "./lib_git_message_prompt.js"
import * as lib_git_message_validate from "./lib_git_message_validate.js"
import * as lib_llm_chat from "./lib_llm_chat.js"
import type {LlmConfig} from "./lib_llm_config.js"
import * as lib_llm_config from "./lib_llm_config.js"
import {PROGRAM_NAME, PROGRAM_VERSION} from "./lib_package_details.js"
import * as lib_tell from "./lib_tell.js"

export default {}

export interface GitMessageGenerateDetails {
  llm_config: LlmConfig
  diffstat: string
  diff: string
}

function add_footer({body, llm_config}: {body: string; llm_config: LlmConfig}): string {
  const {llm_model_name} = llm_config

  const timestamp = lib_datetime.format_local_iso_ymd_hms(new Date())

  const footer = `Generated by: ${PROGRAM_NAME} v${PROGRAM_VERSION} at ${timestamp} using ${llm_model_name}`

  // Ensure there's proper spacing before the footer
  return body.trim() + LF + LF + footer
}

export async function generate_message(details: GitMessageGenerateDetails): Promise<string> {
  const {llm_config, diffstat, diff} = details

  // Create the system prompts
  const system_prompt = lib_git_message_prompt.get_system_prompt()

  // Create the user prompt
  const user_prompt = lib_git_message_prompt.get_user_prompt({
    diffstat,
    diff,
    original: EMPTY,
    use_original: false,
  })

  // Try calling the LLM API to generate a message
  try {
    const llm_response = await lib_llm_chat.call_llm({llm_config, system_prompt, user_prompt})

    // Validate the generated message
    const validation_result = lib_git_message_validate.validate_message(llm_response)

    if (!validation_result.valid) {
      lib_tell.warning(`Generated message failed validation: ${validation_result.reason}`)

      if (validation_result.suggested_fix) {
        lib_tell.info("Using suggested fix")
        return add_footer({body: validation_result.suggested_fix, llm_config})
      }

      // If no fix is suggested, abort
      lib_abort.with_error("Unable to use the generated message")
    }

    // Add a footer to the generated message
    return add_footer({body: llm_response, llm_config})
  } catch {
    lib_abort.with_error(
      `Failed to generate the commit message using LLM ${lib_llm_config.get_llm_model_via(llm_config)}`,
    )
  }
}
