Provides a way to estimate token counts for text based on the LLM model being used. Uses different methods for specific models like GPT variants and falls back to a simple length-based estimate otherwise. Also includes a debug utility to log token usage details when enabled.
